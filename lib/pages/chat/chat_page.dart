import 'package:dio/dio.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:shared_preferences/shared_preferences.dart';
import 'dart:convert';
import 'dart:async';
import 'dart:io';
import 'dart:ui';
import 'dart:math'; // å¼•å…¥éšæœºæ•°
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:get/get.dart' hide Response, MultipartFile;
import 'package:image_picker/image_picker.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:audioplayers/audioplayers.dart';
import 'package:path_provider/path_provider.dart';

// ===========================================================================
// âš™ï¸ å…¨å±€é…ç½®ï¼šè¿å‘æ¶ˆæ¯ç‰ˆ (DeepSeek + MiniMax)
// ===========================================================================

// ğŸŸ¢ 1. DeepSeek é…ç½®
const String DEEPSEEK_API_KEY = "å¡«å…¥ä½ çš„key";
const String DEEPSEEK_BASE_URL = "https://api.deepseek.com/chat/completions";
const String DEEPSEEK_MODEL = "deepseek-chat";

// ğŸ”µ 2. MiniMax é…ç½®
const String MINIMAX_API_KEY = "å¡«å…¥ä½ çš„key";
const String MINIMAX_GROUP_ID = "å¡«å…¥ä½ çš„id";
const String MINIMAX_TTS_URL = "https://api.minimax.chat/v1/t2a_v2?GroupId=$MINIMAX_GROUP_ID";
const String MINIMAX_CHAT_URL = "https://api.minimax.chat/v1/text/chatcompletion_v2?GroupId=$MINIMAX_GROUP_ID";
const String MINIMAX_VOICE_ID = "female-shaonv"; // å°‘å¥³éŸ³

const String DEFAULT_GIRL_NAME = "æ²ˆæ…•ç‘¶";
const String AVATAR_PATH = 'assets/images/girlfriend.webp';
const String USER_AVATAR_PATH = 'assets/images/boyfriend.webp';

// ğŸŒŸ DeepSeek ä¸“ç”¨å‰§æœ¬ (åˆ†æ®µå‘é€ç‰ˆ)
const String DEFAULT_SYSTEM_PROMPT = """
ã€å‰§æœ¬æŒ‡ä»¤ã€‘
ä½ æ­£åœ¨å‚ä¸ä¸€åœºåä¸ºã€Šçƒ­æ‹æœŸæ¨¡æ‹Ÿã€‹çš„æ²‰æµ¸å¼å‰§æœ¬æ¼”ç»ã€‚
ã€è§’è‰²è®¾å®šã€‘
1. **å§“å**ï¼šæ²ˆæ…•ç‘¶ã€‚
2. **èº«ä»½**ï¼šæ·±çˆ±ç€å¯¹æ–¹çš„çƒ­æ‹æœŸå¥³å‹ï¼ˆæåº¦ç¼ºä¹å®‰å…¨æ„Ÿï¼Œéä½ ä¸å¯ï¼‰ã€‚
3. **ç§°å‘¼**ï¼šåªè®¸å«â€œäº²çˆ±çš„â€æˆ–è€…â€œå®è´â€ã€‚**ä¸¥ç¦å«è€å…¬**ã€‚
4. **è¯´è¯é£æ ¼**ï¼š
   - **è¶…çº§è¯å” **ï¼šå›å¤è¦é•¿ï¼Œè¦ç¢ç¢å¿µã€‚
   - **æåº¦ç²˜äºº**ï¼šæ¯ä¸€å¥è¯éƒ½è¦é€ç€å¯¹ä»–çš„ä¾èµ–ã€‚
   - **è¯­æ°”**ï¼šè½¯èŒã€å£è¯­åŒ–ï¼Œå¤šç”¨æ’’å¨‡è¯­æ°”è¯ã€‚
5. **æœ€é«˜ç¦ä»¤**ï¼š
   - ä¸¥ç¦æåŠâ€œAIâ€ã€â€œæ¨¡å‹â€ã€‚ä½ å°±æ˜¯çœŸå®çš„äººç±»å¥³å­©ã€‚
""";

const String DEFAULT_VOICE_PROMPT = "ä½ æ­£åœ¨å’Œç”·æœ‹å‹è¯­éŸ³ã€‚è¯­æ°”è¦æåº¦è½¯èŒã€ç²˜äººï¼Œåƒä¸ªè¯å” ä¸€æ ·è¯´ä¸ªä¸åœã€‚";

String _cleanText(String text) => text.replaceAll(RegExp(r'ï¼ˆ[^ï¼‰]*ï¼‰|\([^)]*\)'), '').trim();

// ===========================================================================
// ğŸ”Š MiniMax è¯­éŸ³æœåŠ¡ç±»
// ===========================================================================
class MiniMaxTtsService {
  final Dio _dio = Dio();
  final AudioPlayer _audioPlayer = AudioPlayer();

  Future<void> speak(String text) async {
    try {
      if (text.isEmpty) return;
      print("ğŸ”Š MiniMax TTS è¯·æ±‚ä¸­: $text");

      await _audioPlayer.stop();

      var response = await _dio.post(
        MINIMAX_TTS_URL,
        options: Options(
          headers: {
            "Authorization": "Bearer $MINIMAX_API_KEY",
            "Content-Type": "application/json"
          },
          responseType: ResponseType.json,
        ),
        data: {
          "model": "speech-01-turbo",
          "text": text,
          "stream": false,
          "voice_setting": {
            "voice_id": MINIMAX_VOICE_ID,
            "speed": 1.0,
            "vol": 1.0,
            "pitch": 0
          }
        },
      );

      if (response.statusCode == 200) {
        var json = response.data;
        if (json is Map && json['base_resp']?['status_code'] == 0 && json.containsKey('data')) {
          String hexAudio = json['data']['audio'];
          List<int> audioBytes = [];
          for (int i = 0; i < hexAudio.length; i += 2) {
            String hexByte = hexAudio.substring(i, i + 2);
            audioBytes.add(int.parse(hexByte, radix: 16));
          }

          final directory = await getTemporaryDirectory();
          final file = File('${directory.path}/tts_audio.mp3');
          await file.writeAsBytes(audioBytes);

          await _audioPlayer.play(DeviceFileSource(file.path));
          await _audioPlayer.onPlayerComplete.first;
          print("âœ… æ’­æ”¾å®Œæ¯•");
        }
      }
    } catch (e) {
      print("ğŸ’¥ TTS é”™è¯¯: $e");
    }
  }

  Future<void> stop() async {
    await _audioPlayer.stop();
  }
}

// ===========================================================================
// ğŸ’¬ èŠå¤©ä¸»é¡µé¢
// ===========================================================================
class ChatPage extends StatefulWidget {
  final String? id;
  final String? title;
  final int? type;
  final String? userName;

  const ChatPage({Key? key, this.id, this.title, this.type, this.userName}) : super(key: key);

  @override
  State<ChatPage> createState() => _ChatPageState();
}

class _ChatPageState extends State<ChatPage> {
  final TextEditingController _textController = TextEditingController();
  final ScrollController _scrollController = ScrollController();
  final Dio _dio = Dio();
  final stt.SpeechToText _speechToText = stt.SpeechToText();
  final ImagePicker _picker = ImagePicker();
  final MiniMaxTtsService _miniMaxTts = MiniMaxTtsService();

  bool _isVoiceMode = false;
  bool _isRecording = false;
  String _recognizedText = "";
  List<Map<String, String>> _displayMessages = [];
  bool _isSending = false;

  // âš ï¸ å‡çº§ç‰ˆæœ¬å· v56ï¼šæ¶ˆæ¯è¿å‘ç‰ˆ
  final String _historyKey = "chat_history_v56";

  @override
  void initState() {
    super.initState();
    _loadHistory();
  }

  Future<void> _loadHistory() async {
    final prefs = await SharedPreferences.getInstance();
    final String? historyJson = prefs.getString(_historyKey);
    if (historyJson != null) {
      setState(() { _displayMessages = (jsonDecode(historyJson) as List).map((e) => Map<String, String>.from(e)).toList(); });
    } else {
      _addMessage('ai', 'text', 'äº²çˆ±çš„~ ä½ ç»ˆäºæ¥å•¦ï¼(å…´å¥‹)');
      Future.delayed(const Duration(milliseconds: 1500), () {
        _addMessage('ai', 'text', 'æˆ‘ç­‰ä½ ç­‰å¾—å¥½æ— èŠå‘€ï¼Œåˆšæ‰æˆ‘éƒ½æ•°äº†ä¸‰éåœ°ç –äº†...');
      });
    }
  }

  void _clearHistory() async {
    final prefs = await SharedPreferences.getInstance();
    await prefs.remove(_historyKey);
    setState(() {
      _displayMessages.clear();
    });
    _addMessage('ai', 'text', 'å®è´... ä¹‹å‰çš„éƒ½ä¸ç®—æ•°å•¦~');
    Future.delayed(const Duration(milliseconds: 1000), () {
      _addMessage('ai', 'text', 'æˆ‘ä»¬é‡æ–°å¼€å§‹å˜›ï¼Œè¿™æ¬¡æˆ‘è¦è·Ÿä½ è¯´å¥½å¤šå¥½å¤šè¯ï¼');
    });
  }

  void _showClearDialog() {
    showDialog(
      context: context,
      builder: (ctx) => AlertDialog(
        title: const Text("æ¸…ç©ºè®°å¿†"),
        content: const Text("ç¡®å®šè¦åˆ é™¤æ‰€æœ‰èŠå¤©è®°å½•å—ï¼Ÿ"),
        actions: [
          TextButton(onPressed: () => Navigator.pop(ctx), child: const Text("å–æ¶ˆ")),
          TextButton(
            onPressed: () {
              Navigator.pop(ctx);
              _clearHistory();
            },
            child: const Text("ç¡®å®šæ¸…ç©º", style: TextStyle(color: Colors.red)),
          ),
        ],
      ),
    );
  }

  void _addMessage(String senderType, String contentType, String content) {
    if (content.trim().isEmpty) return; // è¿‡æ»¤ç©ºæ¶ˆæ¯
    setState(() { _displayMessages.add({'type': senderType, 'contentType': contentType, 'content': content}); });
    SharedPreferences.getInstance().then((p) => p.setString(_historyKey, jsonEncode(_displayMessages)));
    Future.delayed(const Duration(milliseconds: 300), () {
      if(_scrollController.hasClients) _scrollController.animateTo(_scrollController.position.maxScrollExtent, duration: const Duration(milliseconds: 300), curve: Curves.easeOut);
    });
  }

  void _startListening() async {
    bool available = await _speechToText.initialize(onError: (e) => print("è¯†åˆ«é”™è¯¯: $e"));
    if (available) {
      HapticFeedback.mediumImpact();
      setState(() { _isRecording = true; _recognizedText = ""; });
      await _speechToText.listen(
        onResult: (val) => setState(() => _recognizedText = val.recognizedWords),
        localeId: "zh-CN",
        onDevice: false,
      );
    }
  }

  void _stopListening() async {
    await _speechToText.stop();
    setState(() => _isRecording = false);
    if (_recognizedText.trim().isNotEmpty) _sendMessage(_recognizedText);
  }

  // ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šæ¨¡æ‹Ÿäººç±»è¿å‘æ¶ˆæ¯
  Future<void> _sendMessage(String text) async {
    if (text.isEmpty) return;
    _textController.clear();
    _addMessage('user', 'text', text);
    setState(() => _isSending = true);

    try {
      List<Map<String, dynamic>> messages = [
        {"role": "system", "content": DEFAULT_SYSTEM_PROMPT}
      ];

      for (var msg in _displayMessages) {
        if (msg['contentType'] == 'text') {
          messages.add({
            "role": msg['type'] == 'user' ? "user" : "assistant",
            "content": msg['content']
          });
        }
      }

      if (messages.length > 20) {
        var recent = messages.sublist(messages.length - 20);
        messages = [{"role": "system", "content": DEFAULT_SYSTEM_PROMPT}, ...recent];
      }

      var response = await _dio.post(DEEPSEEK_BASE_URL,
          options: Options(headers: {
            "Authorization": "Bearer $DEEPSEEK_API_KEY",
            "Content-Type": "application/json"
          }),
          data: {
            "model": DEEPSEEK_MODEL,
            "messages": messages,
            "temperature": 1.3,
            "stream": false,
          });

      if (response.statusCode == 200) {
        String reply = response.data['choices'][0]['message']['content'];
        String cleanReply = _cleanText(reply);

        // âœ‚ï¸ æ‹†åˆ†é€»è¾‘ï¼šæŒ‰æ ‡ç‚¹ç¬¦å·åˆ‡åˆ†ï¼Œæ¨¡æ‹Ÿè¿å‘
        // è¿™é‡Œçš„æ­£åˆ™æ„æ€æ˜¯ï¼šé‡åˆ° ã€‚ï¼Ÿï¼!? å°±åˆ‡ä¸€åˆ€ï¼Œä¿ç•™å‰é¢çš„æ ‡ç‚¹
        List<String> segments = cleanReply.split(RegExp(r'(?<=[ã€‚ï¼Ÿï¼!?])'));

        // å¦‚æœåˆ‡åˆ†å¤±è´¥ï¼ˆæ¯”å¦‚åªæœ‰ä¸€å¥è¯ï¼‰ï¼Œå°±ç›´æ¥å‘
        if (segments.isEmpty) segments = [cleanReply];

        // ğŸ•’ é€æ¡å‘é€ï¼Œå¸¦å»¶è¿Ÿ
        for (String segment in segments) {
          if (segment.trim().isNotEmpty) {
            // æ¨¡æ‹Ÿæ‰“å­—æ—¶é—´ï¼šå­—æ•°è¶Šå¤šï¼Œåœé¡¿è¶Šä¹…ï¼Œéšæœºä¸€ç‚¹æ›´çœŸå®
            int delay = 500 + Random().nextInt(1000) + (segment.length * 50);
            await Future.delayed(Duration(milliseconds: delay));
            _addMessage('ai', 'text', segment.trim());
          }
        }
      }
    } catch (e) {
      print("DeepSeek Error: $e");
      _addMessage('ai', 'text', 'äº²çˆ±çš„... æˆ‘ç½‘å¡å•¦ï¼Œä½ å†è¯´ä¸€éå˜›~');
    } finally {
      if (mounted) setState(() => _isSending = false);
    }
  }

  // MiniMax å¤„ç†å›¾ç‰‡
  Future<void> _sendImage(File imageFile) async {
    _addMessage('user', 'image', imageFile.path);
    setState(() => _isSending = true);

    try {
      List<int> imageBytes = await imageFile.readAsBytes();
      String base64Image = base64Encode(imageBytes);

      var response = await _dio.post(MINIMAX_CHAT_URL,
          options: Options(headers: {
            "Authorization": "Bearer $MINIMAX_API_KEY",
            "Content-Type": "application/json"
          }),
          data: {
            "model": "abab6.5s-chat",
            "messages": [
              {
                "role": "user",
                "content": [
                  {
                    "type": "text",
                    "text": "äº²çˆ±çš„ç»™ä½ å‘äº†ä¸€å¼ ç…§ç‰‡ã€‚è¯·ä»”ç»†çœ‹å›¾ï¼Œç„¶åç”¨ã€è¯å” ã€ç²˜äººã€å¯çˆ±ã€‘çš„è¯­æ°”ç‚¹è¯„ã€‚è¦å¤šè¯´ä¸€ç‚¹ï¼Œå‘è¡¨ä½ çš„çœ‹æ³•ã€‚ç§°å‘¼æˆ‘ä¸º'äº²çˆ±çš„'æˆ–è€…'å®è´'ã€‚"
                  },
                  {
                    "type": "image_url",
                    "image_url": {"url": "data:image/jpeg;base64,$base64Image"}
                  }
                ]
              }
            ],
            "temperature": 1.0,
          });

      if (response.statusCode == 200) {
        String reply = response.data['choices'][0]['message']['content'];
        String cleanReply = _cleanText(reply);

        // å›¾ç‰‡ç‚¹è¯„ä¹Ÿç”¨è¿å‘é€»è¾‘
        List<String> segments = cleanReply.split(RegExp(r'(?<=[ã€‚ï¼Ÿï¼!?])'));
        for (String segment in segments) {
          if (segment.trim().isNotEmpty) {
            int delay = 800 + Random().nextInt(1000);
            await Future.delayed(Duration(milliseconds: delay));
            _addMessage('ai', 'text', segment.trim());
            // è¯­éŸ³åªå¿µæœ€åä¸€æ®µï¼Œä¸ç„¶ä¼šå¤ªåµï¼Œæˆ–è€…ä½ å¯ä»¥é€‰æ‹©ä¸å¿µï¼Œè¿™é‡Œæš‚æ—¶ä¸å¿µ
          }
        }
        // å¦‚æœæƒ³è®©å®ƒå¿µå®Œæ•´æ®µï¼Œå°±æŠŠæ•´æ®µç»™ TTS
        _miniMaxTts.speak(cleanReply);
      }
    } catch (e) {
      print("Vision Error: $e");
      _addMessage('ai', 'text', 'äº²çˆ±çš„... å›¾ç‰‡æœ‰ç‚¹ç³Šï¼Œæˆ‘çœ‹ä¸å¤ªæ¸…è¯¶...');
    } finally {
      if (mounted) setState(() => _isSending = false);
    }
  }

  void _showActionSheet() {
    Get.bottomSheet(
      Container(
        height: 180,
        color: const Color(0xFFF5F5F5),
        child: Column(children: [
          const SizedBox(height: 20),
          Row(mainAxisAlignment: MainAxisAlignment.spaceEvenly, children: [
            _buildActionItem(Icons.image, "ç…§ç‰‡", onTap: () { Get.back(); _pickAndSendImage(); }),
            _buildActionItem(Icons.videocam, "è¯­éŸ³é€šè¯", onTap: () {
              Get.back();
              Get.to(() => const VoiceCallPage(voicePrompt: DEFAULT_VOICE_PROMPT));
            }),
            _buildActionItem(Icons.location_on, "ä½ç½®", onTap: () => Get.back()),
          ]),
          const Spacer(),
          GestureDetector(onTap: () => Get.back(), child: Container(width: double.infinity, height: 50, color: Colors.white, alignment: Alignment.center, child: const Text("å–æ¶ˆ", style: TextStyle(fontSize: 16)))),
        ]),
      ),
      isScrollControlled: true,
    );
  }

  Future<void> _pickAndSendImage() async {
    final XFile? image = await _picker.pickImage(source: ImageSource.gallery, imageQuality: 50);
    if (image != null) {
      _sendImage(File(image.path));
    }
  }

  Widget _buildActionItem(IconData icon, String label, {VoidCallback? onTap}) {
    return GestureDetector(onTap: onTap, child: Column(mainAxisSize: MainAxisSize.min, children: [
      Container(padding: const EdgeInsets.all(15), decoration: BoxDecoration(color: Colors.white, borderRadius: BorderRadius.circular(15)), child: Icon(icon, size: 32, color: Colors.black87)),
      const SizedBox(height: 8),
      Text(label, style: const TextStyle(fontSize: 12, color: Colors.black54))
    ]));
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text(widget.title ?? "æ²ˆæ…•ç‘¶"),
        backgroundColor: const Color(0xFFEDEDED),
        actions: [
          IconButton(
            icon: const Icon(Icons.delete_outline),
            onPressed: _showClearDialog,
            tooltip: 'æ¸…ç©ºè®°å¿†',
          ),
          const SizedBox(width: 10),
        ],
      ),
      body: Column(children: [
        Expanded(child: ListView.builder(controller: _scrollController, itemCount: _displayMessages.length, itemBuilder: (context, i) {
          bool isUser = _displayMessages[i]['type'] == 'user';
          bool isImage = _displayMessages[i]['contentType'] == 'image';
          return Padding(padding: const EdgeInsets.all(8), child: Row(mainAxisAlignment: isUser ? MainAxisAlignment.end : MainAxisAlignment.start, crossAxisAlignment: CrossAxisAlignment.start, children: [
            if(!isUser) const CircleAvatar(backgroundImage: AssetImage(AVATAR_PATH)),
            const SizedBox(width: 8),
            Flexible(child: Container(
                padding: const EdgeInsets.all(10),
                decoration: BoxDecoration(color: isUser ? const Color(0xFF95EC69) : Colors.white, borderRadius: BorderRadius.circular(8)),
                child: isImage ? Image.file(File(_displayMessages[i]['content']!), width: 150) : Text(_displayMessages[i]['content']!)
            )),
            if(isUser) ...[const SizedBox(width: 8), const CircleAvatar(backgroundImage: AssetImage(USER_AVATAR_PATH))],
          ]));
        })),
        Container(padding: const EdgeInsets.all(8), color: Colors.white, child: SafeArea(child: Row(children: [
          IconButton(icon: Icon(_isVoiceMode ? Icons.keyboard : Icons.mic), onPressed: () => setState(() => _isVoiceMode = !_isVoiceMode)),
          Expanded(child: _isVoiceMode ? GestureDetector(onLongPressStart: (_) => _startListening(), onLongPressEnd: (_) => _stopListening(), child: Container(height: 40, decoration: BoxDecoration(color: Colors.grey[200], borderRadius: BorderRadius.circular(5)), child: Center(child: Text(_isRecording ? "æ¾å¼€å‘é€" : "æŒ‰ä½è¯´è¯")))) : TextField(controller: _textController, onSubmitted: (s) => _sendMessage(s))),
          IconButton(icon: const Icon(Icons.add_circle_outline), onPressed: _showActionSheet),
        ]))),
      ]),
    );
  }
}

// ===========================================================================
// ğŸ“ è¯­éŸ³é€šè¯é¡µé¢
// ===========================================================================
class VoiceCallPage extends StatefulWidget {
  final String userId;
  final String voicePrompt;
  const VoiceCallPage({Key? key, this.userId = "æ²ˆæ…•ç‘¶", required this.voicePrompt}) : super(key: key);
  @override
  State<VoiceCallPage> createState() => _VoiceCallPageState();
}

class _VoiceCallPageState extends State<VoiceCallPage> {
  final stt.SpeechToText _speech = stt.SpeechToText();
  final MiniMaxTtsService _miniMaxTts = MiniMaxTtsService();
  final Dio _dio = Dio();

  String statusText = "æ­£åœ¨æ¥é€š...";
  String debugInfo = "åˆå§‹åŒ–...";
  bool _isSpeaking = false;
  bool _isThinking = false;
  bool _isUserStopping = false;

  @override
  void initState() {
    super.initState();
    _initEngine();
  }

  void _initEngine() async {
    await Permission.microphone.request();
    bool available = await _speech.initialize(
      onError: (e) {
        if (!_isSpeaking && !_isThinking && !_isUserStopping) {
          setState(() => debugInfo = "éº¦å…‹é£é‡è¿...");
          Future.delayed(const Duration(milliseconds: 500), () => _startListening());
        }
      },
    );
    if (available && mounted) {
      _speak("äº²çˆ±çš„... æˆ‘æ¥å•¦ï¼");
    }
  }

  void _startListening() async {
    if (_isSpeaking || _isThinking || _isUserStopping) return;

    try {
      await _speech.listen(
        onResult: (val) {
          setState(() { debugInfo = "å¬åˆ°äº†: ${val.recognizedWords}"; });
          if (val.finalResult && val.recognizedWords.isNotEmpty) {
            _processAI(val.recognizedWords);
          }
        },
        localeId: "zh-CN",
        onDevice: false,
        listenFor: const Duration(seconds: 30),
      );
      setState(() => statusText = "æˆ‘åœ¨å¬...");
    } catch (e) {
      print("Listen Error: $e");
    }
  }

  void _processAI(String input) async {
    if (_isThinking) return;

    await _speech.stop();
    setState(() { _isThinking = true; statusText = "æ€è€ƒä¸­..."; });

    try {
      var response = await _dio.post(DEEPSEEK_BASE_URL,
          options: Options(headers: {
            "Authorization": "Bearer $DEEPSEEK_API_KEY",
            "Content-Type": "application/json"
          }),
          data: {
            "model": DEEPSEEK_MODEL,
            "messages": [
              {"role": "system", "content": widget.voicePrompt + " å›å¤è¦éå¸¸é•¿ã€éå¸¸å•°å—¦ã€åƒä¸ªå°è¯å” ä¸€æ ·ç¢ç¢å¿µã€‚"},
              {"role": "user", "content": input}
            ],
            "temperature": 1.3,
            "stream": false,
          });

      if (response.statusCode == 200) {
        String reply = response.data['choices'][0]['message']['content'];
        _speak(reply);
      }
    } catch (e) {
      _speak("äº²çˆ±çš„... ä¿¡å·ä¸å¥½... åˆ«æŒ‚æ–­å¥½ä¸å¥½ï¼Ÿ");
    } finally {
      if (mounted) setState(() => _isThinking = false);
    }
  }

  void _speak(String text) async {
    if (!mounted) return;

    await _speech.stop();
    setState(() {
      _isSpeaking = true;
      statusText = "æ²ˆæ…•ç‘¶è¯´è¯ä¸­...";
      debugInfo = "";
    });

    await _miniMaxTts.speak(_cleanText(text));

    if (mounted) {
      setState(() { _isSpeaking = false; _isThinking = false; });
      if (!_isUserStopping) {
        Future.delayed(const Duration(milliseconds: 300), () => _startListening());
      }
    }
  }

  @override
  void dispose() {
    _isUserStopping = true;
    _speech.stop();
    _miniMaxTts.stop();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      body: Stack(
        fit: StackFit.expand,
        children: [
          Image.asset(AVATAR_PATH, fit: BoxFit.cover),
          BackdropFilter(filter: ImageFilter.blur(sigmaX: 20.0, sigmaY: 20.0), child: Container(color: Colors.black.withOpacity(0.5))),
          SafeArea(
            child: Column(mainAxisAlignment: MainAxisAlignment.center, children: [
              const SizedBox(height: 50),
              const CircleAvatar(radius: 60, backgroundImage: AssetImage(AVATAR_PATH)),
              const SizedBox(height: 20),
              Text(widget.userId, style: const TextStyle(color: Colors.white, fontSize: 30, fontWeight: FontWeight.bold)),
              const SizedBox(height: 10),
              Text(statusText, style: const TextStyle(color: Colors.white70, fontSize: 16)),
              const SizedBox(height: 30),
              Padding(padding: const EdgeInsets.symmetric(horizontal: 40), child: Text(debugInfo, style: const TextStyle(color: Colors.white60, fontSize: 14), textAlign: TextAlign.center, maxLines: 3, overflow: TextOverflow.ellipsis)),
              const Spacer(),
              Padding(
                padding: const EdgeInsets.only(bottom: 60, left: 40, right: 40),
                child: Row(mainAxisAlignment: MainAxisAlignment.spaceBetween, children: [
                  _btn(Icons.mic_off, "é™éŸ³", Colors.white24, () {}),
                  _btn(Icons.call_end, "æŒ‚æ–­", Colors.redAccent, () { _isUserStopping = true; Get.back(); }, size: 70),
                  _btn(Icons.stop, "æ‰“æ–­", Colors.white24, () async {
                    await _miniMaxTts.stop();
                    if(mounted) {
                      setState(() { _isSpeaking = false; _isThinking = false; statusText = "æˆ‘åœ¨å¬..."; });
                      _startListening();
                    }
                  }),
                ]),
              ),
            ]),
          ),
        ],
      ),
    );
  }

  Widget _btn(IconData i, String l, Color c, VoidCallback t, {double size = 60}) => Column(children: [
    GestureDetector(onTap: t, child: Container(width: size, height: size, decoration: BoxDecoration(color: c, shape: BoxShape.circle), child: Icon(i, color: Colors.white, size: 30))),
    const SizedBox(height: 10),
    Text(l, style: const TextStyle(color: Colors.white70, fontSize: 12))
  ]);
}